# memtool Phase 2.5 æŠ€æœ¯è®¾è®¡æ–¹æ¡ˆ (v2)

> æ ¹æ® Codex CR åé¦ˆä¿®è®¢

## ğŸ“‹ ç‰ˆæœ¬ä¿¡æ¯
- **ç‰ˆæœ¬**: 0.3.0
- **ç›®æ ‡**: ç¨³å®šåŒ– + å¯è§‚æµ‹æ€§ + å‘é‡æœç´¢ä¿®å¤
- **é¢„ä¼°å·¥ä½œé‡**: 2-3 å¤© (é‡‡ç”¨ä¿å®ˆç­–ç•¥)

---

## ğŸ¯ ç›®æ ‡ (ä¿®è®¢å)

| ä¼˜å…ˆçº§ | ç›®æ ‡ | åº¦é‡æ ‡å‡† | å¤‡æ³¨ |
|--------|------|----------|------|
| P0 | ä¿®å¤å‘é‡æœç´¢ | `memory_semantic_search` å¯ç”¨ | æœ¬æ¬¡å¿…é¡»å®Œæˆ |
| P1 | åŸºç¡€å¯è§‚æµ‹æ€§ | `memory_stats` å¯ç”¨ | ç®€åŒ–ç‰ˆ,ä¸å«è¡°å‡ç»Ÿè®¡ |
| P2 | å¥åº·æ£€æŸ¥ | `memory_health_check` å¯ç”¨ | é˜ˆå€¼å¯é…ç½® |
| **P3** | è®°å¿†ç‰ˆæœ¬å†å² | `memory_history` å¯ç”¨ | **æ¨è¿Ÿåˆ° Phase 2.6** |

**ç­–ç•¥è°ƒæ•´**: é‡‡ç”¨ Codex å»ºè®®çš„ä¿å®ˆæ–¹æ¡ˆ,å…ˆç¨³å®šå‘é‡æœç´¢,å†é€æ­¥å¼•å…¥å¤æ‚åŠŸèƒ½ã€‚

---

## ğŸ”§ æ¨¡å—è®¾è®¡

### 1. ChromaDB è¿ç§» (P0) âœ… æ”¹è¿›

**ä¿®æ”¹æ–‡ä»¶**: `memtool/embedding/vector_store.py`

```python
from packaging import version as pkg_version

def _ensure_client(self):
    """Lazy initialization with version-safe API selection"""
    if self._client is not None:
        return
    
    try:
        import chromadb
    except ImportError:
        raise ImportError(
            "chromadb is required for vector search. "
            "Install with: pip install chromadb"
        )
    
    self._persist_dir.mkdir(parents=True, exist_ok=True)
    
    # å¥å£®çš„ç‰ˆæœ¬è§£æ (å¤„ç† rc/alpha/beta ç‰ˆæœ¬)
    try:
        chroma_ver = pkg_version.parse(chromadb.__version__)
        use_new_api = chroma_ver >= pkg_version.parse("0.4.0")
    except Exception:
        # è§£æå¤±è´¥æ—¶é»˜è®¤ä½¿ç”¨æ–° API
        use_new_api = True
        logger.warning(f"Failed to parse ChromaDB version: {chromadb.__version__}, assuming >= 0.4")
    
    if use_new_api:
        self._init_persistent_client()
    else:
        self._init_legacy_client()


def _init_persistent_client(self):
    """ChromaDB 0.4+ API"""
    import chromadb
    from chromadb.config import Settings
    
    self._client = chromadb.PersistentClient(
        path=str(self._persist_dir),
        settings=Settings(
            anonymized_telemetry=False,
            allow_reset=True
        )
    )
    self._collection = self._client.get_or_create_collection(
        name=self._collection_name,
        metadata={"hnsw:space": "cosine"}
    )
    logger.info(f"Initialized ChromaDB (new API): {self._persist_dir}")


def _init_legacy_client(self):
    """ChromaDB < 0.4 API (deprecated)"""
    import chromadb
    from chromadb.config import Settings
    
    self._client = chromadb.Client(Settings(
        chroma_db_impl="duckdb+parquet",
        persist_directory=str(self._persist_dir),
        anonymized_telemetry=False
    ))
    self._collection = self._client.get_or_create_collection(
        name=self._collection_name,
        metadata={"hnsw:space": "cosine"}
    )
    logger.info(f"Initialized ChromaDB (legacy API): {self._persist_dir}")
```

**æ–°å¢ä¾èµ–**: `packaging` (ç”¨äºå®‰å…¨çš„ç‰ˆæœ¬è§£æ)

---

### 2. memory_stats å·¥å…· (P1) âœ… ç®€åŒ–ç‰ˆ

**æ–°å¢æ–‡ä»¶**: `memtool/observability.py`

```python
"""
Observability module for memtool
Phase 2.5: åŸºç¡€ç»Ÿè®¡ (ä¸å«è¡°å‡ç»Ÿè®¡,é¿å… O(n) éå†)
"""
from __future__ import annotations

import logging
import os
from typing import Any, Dict, TYPE_CHECKING

if TYPE_CHECKING:
    from memtool_core import MemoryStore

logger = logging.getLogger(__name__)


def compute_stats(store: "MemoryStore") -> Dict[str, Any]:
    """è®¡ç®—è®°å¿†åº“ç»Ÿè®¡ä¿¡æ¯ (è½»é‡ç‰ˆ)
    
    Phase 2.5: ä»…åŸºç¡€ COUNT/åˆ†å¸ƒç»Ÿè®¡,ä¸å«è¡°å‡è®¡ç®—
    Phase 2.6: å°†å¢åŠ é‡‡æ ·è¡°å‡ç»Ÿè®¡
    """
    conn = store._get_conn()
    
    # åŸºç¡€ç»Ÿè®¡ (å•æ¬¡æŸ¥è¯¢)
    total = conn.execute("SELECT COUNT(*) FROM memory_items").fetchone()[0]
    
    if total == 0:
        return {
            "total_items": 0,
            "by_type": {},
            "by_confidence": {},
            "access": {"avg_count": 0, "max_count": 0, "never_accessed": 0},
            "storage_size_mb": 0,
            "vector_coverage": 0,
        }
    
    # æŒ‰ç±»å‹åˆ†å¸ƒ
    type_rows = conn.execute(
        "SELECT type, COUNT(*) FROM memory_items GROUP BY type"
    ).fetchall()
    type_dist = {row[0] or "unknown": row[1] for row in type_rows}
    
    # æŒ‰ç½®ä¿¡åº¦åˆ†å¸ƒ
    conf_rows = conn.execute(
        "SELECT confidence_level, COUNT(*) FROM memory_items GROUP BY confidence_level"
    ).fetchall()
    confidence_dist = {row[0] or "unknown": row[1] for row in conf_rows}
    
    # è®¿é—®ç»Ÿè®¡ (å•æ¬¡èšåˆæŸ¥è¯¢)
    access_row = conn.execute("""
        SELECT 
            COALESCE(AVG(access_count), 0) as avg_access,
            COALESCE(MAX(access_count), 0) as max_access,
            SUM(CASE WHEN access_count = 0 THEN 1 ELSE 0 END) as never_accessed
        FROM memory_items
    """).fetchone()
    
    # å‘é‡è¦†ç›–ç‡
    vector_coverage = 0.0
    if hasattr(store, '_vector_store') and store._vector_store:
        try:
            vector_count = store._vector_store.count()
            vector_coverage = vector_count / total if total > 0 else 0.0
        except Exception as e:
            logger.warning(f"Failed to get vector count: {e}")
    
    # å­˜å‚¨å¤§å°
    storage_size_bytes = 0
    try:
        db_path = store._db_path
        if os.path.exists(db_path):
            storage_size_bytes = os.path.getsize(db_path)
    except Exception:
        pass
    
    return {
        "total_items": total,
        "by_type": type_dist,
        "by_confidence": confidence_dist,
        "access": {
            "avg_count": round(access_row[0], 2),
            "max_count": access_row[1],
            "never_accessed": access_row[2] or 0
        },
        "storage_size_mb": round(storage_size_bytes / 1024 / 1024, 2),
        "vector_coverage": round(vector_coverage, 3),
    }
```

---

### 3. memory_health_check å·¥å…· (P2) âœ… é˜ˆå€¼å¯é…ç½®

```python
# é»˜è®¤é˜ˆå€¼ (å¯é€šè¿‡é…ç½®è¦†ç›–)
DEFAULT_HEALTH_THRESHOLDS = {
    "stale_ratio_warning": 0.3,      # è¿‡æœŸæ¯”ä¾‹è­¦å‘Šé˜ˆå€¼
    "never_accessed_warning": 0.5,   # ä»æœªè®¿é—®æ¯”ä¾‹è­¦å‘Šé˜ˆå€¼
    "vector_coverage_warning": 0.9,  # å‘é‡è¦†ç›–ç‡è­¦å‘Šé˜ˆå€¼
    "min_items_for_vector_check": 10 # æœ€å°è®°å½•æ•°æ‰æ£€æŸ¥å‘é‡è¦†ç›–
}


def health_check(
    store: "MemoryStore",
    thresholds: Dict[str, float] | None = None
) -> Dict[str, Any]:
    """æ£€æŸ¥è®°å¿†åº“å¥åº·çŠ¶æ€
    
    Args:
        store: MemoryStore å®ä¾‹
        thresholds: å¯é€‰çš„é˜ˆå€¼è¦†ç›–
    """
    # åˆå¹¶é˜ˆå€¼
    th = {**DEFAULT_HEALTH_THRESHOLDS, **(thresholds or {})}
    
    issues = []
    recommendations = []
    
    stats = compute_stats(store)
    total = stats["total_items"]
    
    if total == 0:
        return {
            "ok": True,
            "status": "empty",
            "message": "è®°å¿†åº“ä¸ºç©º",
            "issues": [],
            "recommendations": ["ä½¿ç”¨ memory_store æ·»åŠ ç¬¬ä¸€æ¡è®°å¿†"],
            "stats": stats
        }
    
    # æ£€æŸ¥ä»æœªè®¿é—®çš„è®°å¿†
    never_accessed = stats["access"]["never_accessed"]
    never_accessed_ratio = never_accessed / total
    if never_accessed_ratio > th["never_accessed_warning"]:
        issues.append({
            "type": "low_usage",
            "severity": "info",
            "message": f"{never_accessed} æ¡è®°å¿†ä»æœªè¢«è®¿é—® ({never_accessed_ratio*100:.1f}%)"
        })
    
    # æ£€æŸ¥å‘é‡è¦†ç›–ç‡
    if total >= th["min_items_for_vector_check"]:
        if stats["vector_coverage"] < th["vector_coverage_warning"]:
            issues.append({
                "type": "incomplete_vector_index",
                "severity": "warning",
                "message": f"å‘é‡ç´¢å¼•è¦†ç›–ç‡ {stats['vector_coverage']*100:.1f}%"
            })
            recommendations.append("è¿è¡Œ memory_vector_sync(force=True) é‡å»ºå‘é‡ç´¢å¼•")
    
    # ç¡®å®šæ•´ä½“çŠ¶æ€
    severity_scores = {"critical": 3, "warning": 2, "info": 1}
    max_severity = max(
        [severity_scores.get(i["severity"], 0) for i in issues],
        default=0
    )
    
    if max_severity >= 3:
        status = "unhealthy"
        ok = False
    elif max_severity >= 2:
        status = "degraded"
        ok = True  # degraded ä»ç„¶ ok,åªæ˜¯æœ‰è­¦å‘Š
    else:
        status = "healthy"
        ok = True
    
    return {
        "ok": ok,
        "status": status,
        "issues": issues,
        "recommendations": recommendations,
        "stats": stats,
        "thresholds_used": th  # è¿”å›ä½¿ç”¨çš„é˜ˆå€¼,ä¾¿äºè°ƒè¯•
    }
```

---

### 4. æ€§èƒ½ä¼˜åŒ– (P2) âœ… æ”¹è¿›é”™è¯¯å¤„ç†

```python
def _track_access_batch(self, item_ids: List[str]) -> bool:
    """æ‰¹é‡æ›´æ–°è®¿é—®è®°å½•
    
    Returns:
        bool: True if successful, False otherwise
    """
    if not item_ids:
        return True
    
    try:
        conn = self._get_conn()
        now = utcnow_iso()
        
        placeholders = ",".join("?" * len(item_ids))
        conn.execute(f"""
            UPDATE memory_items
            SET access_count = access_count + 1,
                last_accessed_at = ?
            WHERE id IN ({placeholders})
        """, [now] + item_ids)
        
        conn.commit()
        return True
        
    except sqlite3.Error as e:
        # ä¸åé”™è¯¯,è®°å½•æ—¥å¿—
        logger.warning(f"Failed to track access for {len(item_ids)} items: {e}")
        return False
```

---

### 5. ç±»å˜é‡ä¿®å¤ (P2) âœ…

**ä¿®æ”¹æ–‡ä»¶**: `memtool/embedding/semantic.py`

```python
class SemanticSearchMixin:
    """Mixin for semantic search capabilities
    
    æ³¨æ„: æ‰€æœ‰çŠ¶æ€å˜é‡éƒ½æ˜¯å®ä¾‹å˜é‡,ä¸æ˜¯ç±»å˜é‡
    """
    
    def _init_vector_attrs(self) -> None:
        """Initialize vector store attributes
        
        å¿…é¡»åœ¨ __init__ ä¸­è°ƒç”¨æ­¤æ–¹æ³•
        """
        self._vector_store: Optional[VectorStore] = None
        self._vector_lock: threading.Lock = threading.Lock()
        self._vector_initialized: bool = False
```

åœ¨ `MemoryStore.__init__` ä¸­è°ƒç”¨:
```python
def __init__(self, db_path: str) -> None:
    self._db_path = db_path
    self._pool = SQLiteConnectionPool(db_path)
    self._init_vector_attrs()  # åˆå§‹åŒ–å‘é‡ç›¸å…³å®ä¾‹å˜é‡
```

---

## ğŸ“ æ–‡ä»¶å˜æ›´æ¸…å• (ä¿®è®¢å)

| æ–‡ä»¶ | å˜æ›´ç±»å‹ | æè¿° |
|------|----------|------|
| `memtool/embedding/vector_store.py` | ä¿®æ”¹ | ChromaDB API è¿ç§» + ç‰ˆæœ¬å®‰å…¨è§£æ |
| `memtool/embedding/semantic.py` | ä¿®æ”¹ | ç±»å˜é‡â†’å®ä¾‹å˜é‡ |
| `memtool/observability.py` | **æ–°å¢** | stats + health_check (ç®€åŒ–ç‰ˆ) |
| `memtool_core.py` | ä¿®æ”¹ | æ‰¹é‡è¿½è¸ª + é”™è¯¯æ—¥å¿— |
| `mcp_server.py` | ä¿®æ”¹ | æ–°å¢ 2 ä¸ª MCP å·¥å…· |
| `pyproject.toml` | ä¿®æ”¹ | æ·»åŠ  packaging ä¾èµ– |

---

## ğŸ“Š æ–°å¢ MCP å·¥å…· (ä¿®è®¢å)

| å·¥å…·å | æè¿° | å‚æ•° |
|--------|------|------|
| `memory_stats` | è·å–ç»Ÿè®¡ä¿¡æ¯ | db_path? |
| `memory_health_check` | å¥åº·æ£€æŸ¥ | db_path?, thresholds? |

**æ¨è¿Ÿåˆ° Phase 2.6**:
- `memory_history` (éœ€è¦å®Œæ•´çš„äº‹åŠ¡å†™å…¥ç­–ç•¥)
- è¡°å‡ç»Ÿè®¡ (éœ€è¦é‡‡æ ·ç­–ç•¥)

---

## âœ… éªŒæ”¶æ ‡å‡† (ä¿®è®¢å)

### P0: å‘é‡æœç´¢
```bash
mcporter call memtool.memory_semantic_search query:"æµ‹è¯•"
# è¿”å› ok: true, items: [...]
```

### P1: ç»Ÿè®¡ä¿¡æ¯
```bash
mcporter call memtool.memory_stats
# è¿”å› total_items, by_type, access, vector_coverage
```

### P2: å¥åº·æ£€æŸ¥
```bash
mcporter call memtool.memory_health_check
# è¿”å› status: healthy/degraded/unhealthy, issues, recommendations
```

---

## ğŸš€ å®æ–½æ­¥éª¤

1. **Day 1**: ChromaDB è¿ç§» + æµ‹è¯•
   - å®ç°ç‰ˆæœ¬å®‰å…¨è§£æ
   - æµ‹è¯•æ–°æ—§ API å…¼å®¹
   - éªŒè¯ semantic_search å¯ç”¨

2. **Day 2**: å¯è§‚æµ‹æ€§
   - å®ç° `observability.py`
   - æ³¨å†Œ MCP å·¥å…·
   - ä¿®å¤ç±»å˜é‡é—®é¢˜
   - æ”¹è¿›é”™è¯¯æ—¥å¿—

3. **Day 3**: æµ‹è¯• + æ–‡æ¡£
   - é›†æˆæµ‹è¯•
   - æ›´æ–° README
   - å‘å¸ƒ 0.3.0

---

## ğŸ“ Phase 2.6 é¢„è§ˆ (åç»­)

- `memory_history`: ç‰ˆæœ¬å†å² (éœ€è®¾è®¡äº‹åŠ¡å†™å…¥)
- è¡°å‡ç»Ÿè®¡: é‡‡æ ·ç­–ç•¥ (é¿å… O(n) å…¨è¡¨æ‰«æ)
- è®°å¿†åˆå¹¶: ç›¸ä¼¼è®°å¿†è‡ªåŠ¨åˆå¹¶å»ºè®®
